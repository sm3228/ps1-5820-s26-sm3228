{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5451999-c880-4c5c-909c-1f763676eee7",
   "metadata": {},
   "source": [
    "# Problem Set 1 (PS1): Overlapping K-means Test Case with Synthetic Data\n",
    "We introduced the [K-means clustering algorithm](docs/CHEME-5820-L1d-KMeans-Algorithm-Spring-2026.ipynb). The [K-means approach](https://en.wikipedia.org/wiki/K-means_clustering) is straightforward, but it has several limitations, such as the necessity to specify the number of clusters in advance. More significant issues arise with overlapping datasets or non-convex datasets. \n",
    "\n",
    "Let's explore a problem mentioned [in the MAT 180 Big Data course at UC Davis](https://www.math.ucdavis.edu/~strohmer/courses/180BigData/180coursematerial.html). Consider two circular data clouds, each of radius 1, and their centers are a distance $d$ apart. As long as $d > 2.08$, [K-means clustering](https://en.wikipedia.org/wiki/K-means_clustering) yields the correct answer. But if $d\\leq{2.08}$, [K-means clustering](https://en.wikipedia.org/wiki/K-means_clustering) may fail. Moreover, this is the failure of [K-means](https://en.wikipedia.org/wiki/K-means_clustering) and not of Lloyd's algorithm, i.e., Lloyd's algorithm will converge, but to an incorrect answer.\n",
    "\n",
    "> __Learning Objectives__\n",
    "> \n",
    "> By the end of this activity, you will be able to:\n",
    "> \n",
    "> * __Generate synthetic overlapping datasets:__ Create circular data clouds with controlled separation distances to test clustering algorithm behavior in distinct versus overlapping configurations.\n",
    "> * __Apply K-means clustering to non-convex data:__ Implement K-means clustering on synthetic datasets and visualize how the algorithm partitions data when cluster centers are separated by varying distances.\n",
    "> * __Evaluate clustering quality using multiple metrics:__ Compute silhouette scores and classification error rates to quantify clustering performance and identify the critical distance threshold where K-means fails.\n",
    "\n",
    "\n",
    "Let's get started!\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2763ee4-d505-4b77-8065-311f00b14b85",
   "metadata": {},
   "source": [
    "## Setup, Data, and Prerequisites\n",
    "First, we set up the computational environment by including the `Include.jl` file and loading any needed resources.\n",
    "\n",
    "> The [`include(...)` command](https://docs.julialang.org/en/v1/base/base/#include) evaluates the contents of the input source file, `Include.jl`, in the notebook's global scope. The `Include.jl` file sets paths, loads required external packages, etc. For additional information on functions and types used in this material, see the [Julia programming language documentation](https://docs.julialang.org/en/v1/). \n",
    "\n",
    "Let's set up our code environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2430897-9ae3-42f5-b795-e9bed7c9b9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "include(joinpath(@__DIR__, \"Include.jl\")); # include the Include.jl file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0ef0f3",
   "metadata": {},
   "source": [
    "In addition to standard Julia libraries, we'll also use [the `VLDataScienceMachineLearningPackage.jl` package](https://github.com/varnerlab/VLDataScienceMachineLearningPackage.jl). Check out [the documentation](https://varnerlab.github.io/VLDataScienceMachineLearningPackage.jl/dev/) for more information on the functions, types, and data used in this material."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487ecef2-fcd0-4338-b20b-4a0243ae3976",
   "metadata": {},
   "source": [
    "### Constants\n",
    "Next, let's set some constants. See the comment next to the constant for a description of what it is, permissible values, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84636cd4-1984-49d2-9983-4dab0cdc9768",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_label_one = 500; # number of points in cloud 1 (must be ≥ 2)\n",
    "number_label_two = 500; # number of points in cloud 2 (must be ≥ 2)\n",
    "total_number_of_points = (number_label_one + number_label_two);\n",
    "number_of_features = 3; # features: (x,y,l), where l is a faux label; see below.\n",
    "c̄₁ = (1.0, 1.0); # center for cluster 1: fixed\n",
    "c̄₂ = (4.0, 1.0); # center for cluster 2: variable, we'll change this in our study\n",
    "maxiter = 10000; # maximum iterations of our K-means implementation\n",
    "K = 2; # number of clusters. We'll change this in our study (K > 1)\n",
    "ϵ = 1e-6; # tolerance for termination. We can set this to whatever we want\n",
    "\n",
    "# Validate the constants\n",
    "@assert number_label_one ≥ 2 \"Cloud 1 must have at least 2 points, got $(number_label_one)\"\n",
    "@assert number_label_two ≥ 2 \"Cloud 2 must have at least 2 points, got $(number_label_two)\"\n",
    "@assert K ≥ 2 \"K must be at least 2 for clustering, got $(K)\"\n",
    "@assert maxiter > 0 \"Maximum iterations must be positive, got $(maxiter)\"\n",
    "#first draft"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780fff6a-eb15-4157-9b40-013c19759477",
   "metadata": {},
   "source": [
    "Check if the distances between the centers are greater than (or less than) the critical threshold. We'll return the distance and a label for the case we are exploring. Distances are calculated [using methods exported by the `Distances.jl` package](https://github.com/JuliaStats/Distances.jl). In this case (and throughout), we [use the Euclidean distance](https://en.wikipedia.org/wiki/Euclidean_distance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3100a62-37db-48fd-b491-7d5dd850a478",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "MethodError: no method matching isless(::String, ::Float64)\nThe function `isless` exists, but no method is defined for this combination of argument types.\n\n\u001b[0mClosest candidates are:\n\u001b[0m  isless(\u001b[91m::Missing\u001b[39m, ::Any)\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m\u001b[4mmissing.jl:87\u001b[24m\u001b[39m\n\u001b[0m  isless(\u001b[91m::Static.StaticFloat64{X}\u001b[39m, ::AbstractFloat) where X\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[36mStatic\u001b[39m \u001b[90m~/.julia/packages/Static/d7YOk/src/\u001b[39m\u001b[90m\u001b[4mfloat.jl:91\u001b[24m\u001b[39m\n\u001b[0m  isless(\u001b[91m::ForwardDiff.Dual{Tx}\u001b[39m, ::AbstractFloat) where Tx\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[33mForwardDiff\u001b[39m \u001b[90m~/.julia/packages/ForwardDiff/9ocoj/src/\u001b[39m\u001b[90m\u001b[4mdual.jl:158\u001b[24m\u001b[39m\n\u001b[0m  ...\n",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching isless(::String, ::Float64)\nThe function `isless` exists, but no method is defined for this combination of argument types.\n\n\u001b[0mClosest candidates are:\n\u001b[0m  isless(\u001b[91m::Missing\u001b[39m, ::Any)\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m\u001b[4mmissing.jl:87\u001b[24m\u001b[39m\n\u001b[0m  isless(\u001b[91m::Static.StaticFloat64{X}\u001b[39m, ::AbstractFloat) where X\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[36mStatic\u001b[39m \u001b[90m~/.julia/packages/Static/d7YOk/src/\u001b[39m\u001b[90m\u001b[4mfloat.jl:91\u001b[24m\u001b[39m\n\u001b[0m  isless(\u001b[91m::ForwardDiff.Dual{Tx}\u001b[39m, ::AbstractFloat) where Tx\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[33mForwardDiff\u001b[39m \u001b[90m~/.julia/packages/ForwardDiff/9ocoj/src/\u001b[39m\u001b[90m\u001b[4mdual.jl:158\u001b[24m\u001b[39m\n\u001b[0m  ...\n",
      "",
      "Stacktrace:",
      " [1] \u001b[0m\u001b[1m<\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mx\u001b[39m::\u001b[0mString, \u001b[90my\u001b[39m::\u001b[0mFloat64\u001b[0m\u001b[1m)\u001b[22m",
      "\u001b[90m   @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4moperators.jl:399\u001b[24m\u001b[39m",
      " [2] \u001b[0m\u001b[1m<=\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mx\u001b[39m::\u001b[0mString, \u001b[90my\u001b[39m::\u001b[0mFloat64\u001b[0m\u001b[1m)\u001b[22m",
      "\u001b[90m   @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4moperators.jl:448\u001b[24m\u001b[39m",
      " [3] top-level scope",
      "\u001b[90m   @\u001b[39m \u001b[90m\u001b[4mIn[8]:13\u001b[24m\u001b[39m",
      " [4] \u001b[0m\u001b[1meval\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mm\u001b[39m::\u001b[0mModule, \u001b[90me\u001b[39m::\u001b[0mAny\u001b[0m\u001b[1m)\u001b[22m",
      "\u001b[90m   @\u001b[39m \u001b[90mCore\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mboot.jl:489\u001b[24m\u001b[39m"
     ]
    }
   ],
   "source": [
    "# STUDENT TASK: Compute `distance` and `case_label`.\n",
    "# Complete the missing code below\n",
    "# HINT: Use Euclidean() distance metric and check if distance ≤ 2.08\n",
    "# If you get stuck, see the solution notebook for the complete implementation\n",
    "\n",
    "distance, case_label = let\n",
    "    \n",
    "    d = Euclidean(); # Euclidean distance measure from the Distances.jl package\n",
    "    distance = # compute the distance between c̄₁ and c̄₂ using d(...)\n",
    "\n",
    "    # Set case_label to \"overlapping\" if distance ≤ 2.08, else \"distinct\"\n",
    "    case_label = \"distinct\"\n",
    "    if (distance ≤ 2.08)\n",
    "        # uncomment and complete → case_label = ...\n",
    "    end\n",
    "\n",
    "    # return the data to the calling scope\n",
    "    distance, case_label    \n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55ad83dc-eeba-4f77-970c-4fff09f0e3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STUDENT TASK: After you compute distance and case_label, print them here.\n",
    "# Uncomment and run the line below after completing the previous cell\n",
    "# println(\"Distance: $(distance) with case_label: $(case_label)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42464041-a1a9-4bf2-bc79-f1f33f735143",
   "metadata": {},
   "source": [
    "Finally, let's set up the color dictionary to visualize the clustering results. The keys of the `my_color_dictionary::Dict{Int64, RGB}` dictionary are the cluster indexes, while the values are the colors mapped to that index. We have initially specified colors for up to three clusters. If you want more clusters, you'll need to specify additional colors. See [the `Colors.jl` package](https://github.com/JuliaGraphics/Colors.jl?tab=readme-ov-file) for details on how to specify (and model) colors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e74203a-6a94-4182-a6fe-47124ee08bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_color_dictionary = Dict{Int64,RGB}();\n",
    "my_color_dictionary[1] = colorant\"#03045e\";\n",
    "my_color_dictionary[2] = colorant\"#e36414\";\n",
    "my_color_dictionary[3] = colorant\"#00b4d8\";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51f1f9f",
   "metadata": {},
   "source": [
    "### Implementation\n",
    "Before generating our synthetic dataset, we need to define helper functions for data generation and quality assessment. These functions will generate circular data clouds, create circle boundaries for visualization, and compute silhouette scores to evaluate clustering quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "861eeeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    fixedcircle(center::Tuple{Float64,Float64}; number_of_points::Int = 100, radius::Float64 = 1.0) -> Array{Float64,2}\n",
    "\n",
    "Generate random data points around a center point that lie on a circle.\n",
    "\n",
    "### Arguments\n",
    "- `center::Tuple{Float64, Float64}`: The center point around which the data points will be generated.\n",
    "- `number_of_points::Int = 100`: The number of data points to generate.\n",
    "- `radius::Float64 = 1.0`: The radius of the circle around the center point. Default value is 1.0.\n",
    "\n",
    "### Returns\n",
    "- A 2D array of data points. The first two columns are the x and y coordinates of the data points.\n",
    "\"\"\"\n",
    "function fixedcircle(center::Tuple{Float64,Float64}; \n",
    "    number_of_points::Int = 100, radius::Float64 = 1.0)::Array{Float64,2}\n",
    "\n",
    "    # initialize -\n",
    "    data = zeros(number_of_points, 2);\n",
    "    θ = range(0, 2π, length=number_of_points);\n",
    "\n",
    "    # generate the data -\n",
    "    for i ∈ 1:number_of_points\n",
    "        # generate random data points -\n",
    "        data[i,1] = center[1] + radius * cos(θ[i]); # x\n",
    "        data[i,2] = center[2] + radius * sin(θ[i]); # y\n",
    "    end\n",
    "\n",
    "    # return -\n",
    "    return data;\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52b0c14",
   "metadata": {},
   "source": [
    "The `fixedcircle(...)` function generates evenly spaced points on a circle boundary for visualization purposes. We'll use this to overlay circle boundaries on our plots to show the true extent of each data cloud.\n",
    "\n",
    "Next, let's define the data generation function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8e2e1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    generatedatacloud(center::Tuple{Float64,Float64}; number_of_points::Int = 100, radius::Float64 = 1.0, label::Int64 = 1) -> Array{Float64,2}\n",
    "\n",
    "Generate random data points around a center point that have a label, and radius less than equal to the given radius.\n",
    "\n",
    "### Arguments\n",
    "- `center::Tuple{Float64,Float64}`: The center point around which the data points will be generated.\n",
    "- `number_of_points::Int = 100`: The number of data points to generate.\n",
    "- `radius::Float64 = 1.0`: The radius of the circle around the center point. Default value is 1.0.\n",
    "- `label::Int64 = 1`: The label to assign to the data points. Default value is 1.\n",
    "\n",
    "### Returns\n",
    "- A 2D array of data points. The first two columns are the x and y coordinates of the data points, and the third column is the label.\n",
    "\"\"\"\n",
    "function generatedatacloud(center::Tuple{Float64,Float64}; \n",
    "    number_of_points::Int = 100, radius::Float64 = 1.0, label::Int64 = 1)::Array{Float64,2}\n",
    "\n",
    "    # initialize -\n",
    "    data = zeros(number_of_points, 3);\n",
    "\n",
    "    # generate the data -\n",
    "    for i ∈ 1:number_of_points\n",
    "        \n",
    "        θ = rand() * 2π; # random angle\n",
    "        r = rand() * radius; # random radius\n",
    "\n",
    "        # generate random data points -\n",
    "        data[i,1] = center[1] + r * cos(θ); # x\n",
    "        data[i,2] = center[2] + r * sin(θ); # y\n",
    "        data[i,3] = label; # label\n",
    "    end\n",
    "\n",
    "    # return -\n",
    "    return data;\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b295ce",
   "metadata": {},
   "source": [
    "The `silhouette(...)` function computes the silhouette score for each data point based on the mathematical definition we'll encounter in Task 3. This implementation uses Euclidean distance by default and returns cohesion, separation, and silhouette values for each point.\n",
    "\n",
    "Let's implement the silhouette function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ece1070",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    silhouette(data::Array{<:Number,2}, assignments::Array{Int,1}; d = Euclidean())\n",
    "\n",
    "This function calculates the silhouette score for each data point in the data set. The silhouette score is a measure of how similar an object is to its own cluster (cohesion) \n",
    "compared to other clusters (separation). The silhouette score ranges from -1 to 1, where a high value indicates that the object is well matched to its own cluster and poorly matched to neighboring clusters.\n",
    "\n",
    "### Arguments\n",
    "- `data::Array{<:Number,2}`: A 2D array of data points that we will cluster. Features are along the columns, and data points are along the rows.\n",
    "- `assignments::Array{Int,1}`: A 1D array of integers that tells us which cluster each data point belongs to.\n",
    "- `d::MyAbstractDistanceMetric = Euclidean()`: The distance metric for the clustering algorithm. This is an optional argument and defaults to the Euclidean distance.\n",
    "\n",
    "### Returns\n",
    "- A 1D array of silhouette scores, one for each data point in the data set.\n",
    "\"\"\"\n",
    "function silhouette(data::Array{<:Number,2}, assignments::Array{Int,1}; d = Euclidean())::Array{Float64,2}\n",
    "    \n",
    "    # initialize -\n",
    "    number_of_points = size(data, 1);\n",
    "    K = length(unique(assignments));\n",
    "    s = zeros(Float64, number_of_points);\n",
    "    a = zeros(Float64, number_of_points);\n",
    "    b = zeros(Float64, number_of_points);\n",
    "    tmp = zeros(Float64, K);\n",
    "    result = Array{Float64,2}(undef, number_of_points, 3);\n",
    "    \n",
    "    # calculate the silhouette -\n",
    "    for i ∈ 1:number_of_points\n",
    "        for k ∈ 1:K\n",
    "            tmp[k] = mean([d(data[i,:], data[j,:]) for j ∈ findall(x-> x == k, assignments)]);\n",
    "        end\n",
    "        a[i] = tmp[assignments[i]];\n",
    "        b[i] = minimum([tmp[k] for k ∈ 1:K if k ≠ assignments[i]]);\n",
    "        s[i] = (b[i] - a[i]) / max(a[i], b[i]);\n",
    "    end\n",
    "\n",
    "    # package the results -\n",
    "    for i ∈ 1:number_of_points\n",
    "        result[i,1] = a[i]; # first column is the a value\n",
    "        result[i,2] = b[i]; # second column is the b value\n",
    "        result[i,3] = s[i]; # third column is the silhouette score\n",
    "    end\n",
    "    \n",
    "    # return -\n",
    "    return result;\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376bda02",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edf69b1-8e4b-4339-b3b9-12181d7224e7",
   "metadata": {},
   "source": [
    "## Task 1: Generation of a synthetic dataset\n",
    "In this task, we'll generate a synthetic dataset $\\mathcal{D} = \\left\\{\\mathbf{x}_{1},\\mathbf{x}_{2},\\dots,\\mathbf{x}_{n}\\right\\}$ in which the data points are random $(x,y)$ values which are members of two circular data clouds.\n",
    "\n",
    "> The first cloud will have center $\\bar{c}_{1} = (1,1)$, while the second cloud center $\\bar{c}_{2}$ will be variable (both center values are specified in the setup section of the notebook). Each cloud has a radius equal to `1`. In addition to the $(x,y)$ values, when generating each element of the data cloud, we give it a `faux` label $l$ of either $l\\in\\{1,2\\}$. The label $l$ is for visualization and quality purposes (we'll exclude it in the clustering operations).\n",
    "\n",
    "To generate the dataset, we'll follow this strategy:\n",
    "\n",
    "> __Strategy__\n",
    ">\n",
    "> First, generate the $l = 1$ and $l=2$ datasets using the `generatedatacloud(...)` function defined above. Then randomly permute the dataset so that the $l = 1$ and $l = 2$ points are not in any particular order. Store the randomized dataset (with the `faux` label) in the $\\hat{\\mathcal{D}}$ `::Array{Float64,2}` variable. Each row of $\\hat{\\mathcal{D}}$ is a data point, while each column corresponds to a feature, i.e., the $x$, $y$, or $l$ value. \n",
    "\n",
    "Let's consider the dataset $\\hat{\\mathcal{D}}$ as the ground truth: data points with `faux` label $l=1$ belong together, and likewise, $l=2$ data points should be clustered together. Let's generate the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "99da4261-eaeb-4b57-9969-75746ce5ad23",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "BoundsError: attempt to access 2-element Vector{Nothing} at index [740, 1]",
     "output_type": "error",
     "traceback": [
      "BoundsError: attempt to access 2-element Vector{Nothing} at index [740, 1]",
      "",
      "Stacktrace:",
      " [1] \u001b[0m\u001b[1mthrow_boundserror\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mA\u001b[39m::\u001b[0mVector\u001b[90m{Nothing}\u001b[39m, \u001b[90mI\u001b[39m::\u001b[0mTuple\u001b[90m{Int64, Int64}\u001b[39m\u001b[0m\u001b[1m)\u001b[22m",
      "\u001b[90m   @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4messentials.jl:15\u001b[24m\u001b[39m",
      " [2] \u001b[0m\u001b[1mcheckbounds\u001b[22m",
      "\u001b[90m   @\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mabstractarray.jl:699\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m",
      " [3] \u001b[0m\u001b[1mgetindex\u001b[22m\u001b[0m\u001b[1m(\u001b[22m::\u001b[0mVector\u001b[90m{Nothing}\u001b[39m, ::\u001b[0mInt64, ::\u001b[0mInt64\u001b[0m\u001b[1m)\u001b[22m",
      "\u001b[90m   @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4marray.jl:928\u001b[24m\u001b[39m",
      " [4] top-level scope",
      "\u001b[90m   @\u001b[39m \u001b[90m\u001b[4mIn[20]:14\u001b[24m\u001b[39m",
      " [5] \u001b[0m\u001b[1meval\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mm\u001b[39m::\u001b[0mModule, \u001b[90me\u001b[39m::\u001b[0mAny\u001b[0m\u001b[1m)\u001b[22m",
      "\u001b[90m   @\u001b[39m \u001b[90mCore\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mboot.jl:489\u001b[24m\u001b[39m"
     ]
    }
   ],
   "source": [
    "D̂ = let\n",
    "\n",
    "    # initialize -\n",
    "    D = Array{Float64,2}(undef, total_number_of_points, number_of_features);\n",
    "    s₁ = nothing; # STUDENT TASK: generate label 1 data\n",
    "    s₂ = nothing; # STUDENT TASK: generate label 2 data\n",
    "\n",
    "    # mix s₁, s₂ together (randomly)\n",
    "    tmp = vcat(s₁,s₂)\n",
    "    random_perm_index_vector = randperm(total_number_of_points);\n",
    "    for i ∈ eachindex(random_perm_index_vector)\n",
    "        k = random_perm_index_vector[i]; # get the from col -\n",
    "        for j ∈ 1:number_of_features\n",
    "            D[i,j] = tmp[k,j];\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    D # return\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "00ccac2c-fda5-49de-9ef2-0efc5461e443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STUDENT TASK: After you build D̂, display it here.\n",
    "# Uncomment the line below to display D̂\n",
    "# D̂"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed77c6a7-8c6a-4ba4-a99d-33b713183e72",
   "metadata": {},
   "source": [
    "### Visualize the initial data clouds\n",
    "`Unhide` the code block below to see how we plotted the initial synthetic dataset using [the `Plots.jl` package](https://github.com/JuliaPlots/Plots.jl), and mainly the [`scatter(...)` function](https://docs.juliaplots.org/stable/api/#Plots.scatter-Tuple). \n",
    "\n",
    "> __Summary__: Depending upon your choice of the second center tuple $\\bar{c}_{2}$, you should have two clouds of data points that are `distinct` or `overlapping.` We have the black cloud of points for data with the `faux` label $l = 1$, while the gray points indicate the `faux` label $l = 2$. \n",
    ">\n",
    ">As the distance between the centers decreases, the two clouds will overlap into a region containing a mixture of both labels. We expect [the K-means approach](https://en.wikipedia.org/wiki/K-means_clustering) will correctly capture distinct data clouds but fail with the overlapping case.\n",
    "\n",
    "So what do you see?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a925c0f1-2c2a-426f-a33f-874ef5981eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STUDENT TASK: After you build D̂, uncomment the entire block below to visualize.\n",
    "# (Visualization code is provided - just remove the #= and =# markers)\n",
    "#=\n",
    "let\n",
    "\n",
    "    dataset = D̂; # what dataset am I looking at?\n",
    "    horizontal_index = 1;\n",
    "    vertical_index = 2;\n",
    "    p = plot(bg=\"gray95\", background_color_outside=\"white\", framestyle = :box, fg_legend = :transparent); # make an empty plot\n",
    "    \n",
    "    circle_one = fixedcircle(c̄₁);\n",
    "    circle_two = fixedcircle(c̄₂);\n",
    "\n",
    "    for i ∈ 1:total_number_of_points\n",
    "        label = dataset[i,3]; # label\n",
    "        c = :black;\n",
    "        if label == 2\n",
    "            c = :gray60\n",
    "        end\n",
    "        scatter!([dataset[i, horizontal_index]], [dataset[i, vertical_index]], label=\"\", mec=:navy, c=c)\n",
    "    end\n",
    "    \n",
    "    scatter!([c̄₁[1]], [c̄₁[2]], ms=6, mec=:black, c=:white, label=\"\")\n",
    "    scatter!([c̄₂[1]], [c̄₂[2]], ms=6, mec=:gray60, c=:white, label=\"\")\n",
    "    plot!(circle_one[:,1], circle_one[:,2], lw=2, c=:black, ls=:dash, label=\"\")\n",
    "    plot!(circle_two[:,1], circle_two[:,2], lw=2, c=:gray60, ls=:dash, label=\"\") \n",
    "    xlabel!(\"Feature 1 (AU)\", fontsize=18);\n",
    "    ylabel!(\"Feature 2 (AU)\", fontsize=18);\n",
    "    title!(\"Case = $(case_label)\", fontsize=18)\n",
    "end\n",
    "=#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d99b582",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a6960d-631d-40b4-8fc9-3ec14d7c8d6c",
   "metadata": {},
   "source": [
    "## Task 2: Cluster the data\n",
    "In this task, we'll cluster the dataset $\\mathcal{D}$ where we exclude the `faux` label, i.e., we consider only the $(x,y)$ data in the dataset. First, we'll build a `model::MyNaiveKMeansClusteringAlgorithm` instance holding information about the problem we are looking to solve; then, we'll cluster the data using [the `cluster(...)` method](https://varnerlab.github.io/VLDataScienceMachineLearningPackage.jl/dev/clustering/#VLDataScienceMachineLearningPackage.cluster).\n",
    "\n",
    "Let's start by constructing the dataset $\\mathcal{D}$ (no hat) from $\\hat{\\mathcal{D}}$ by removing the column corresponding to the `faux` label $l$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0f40dd45-0a8d-46e4-a118-e7bc7d78c692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STUDENT TASK: Create D by dropping the faux label column from D̂.\n",
    "# Use array slicing to select all rows but only columns 1 and 2\n",
    "# HINT: D̂[:,1:end-1] selects all rows and columns 1 through second-to-last\n",
    "D = nothing; # Replace with your slicing code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70851eeb-e0c8-426b-a6e4-65779b7c57b2",
   "metadata": {},
   "source": [
    "Next, let's build the model instance. The `model::MyNaiveKMeansClusteringAlgorithm` contains the data that we passed in, as well as two derived fields that we computed in [the `build(...)` method](https://varnerlab.github.io/VLDataScienceMachineLearningPackage.jl/dev/clustering/#VLDataScienceMachineLearningPackage.build-Tuple{Type{MyNaiveKMeansClusteringAlgorithm},%20NamedTuple}), the centroids and initial assignments. \n",
    "\n",
    "> __Initially__:\n",
    "> \n",
    "> * The `centroids::Dict{Int64, Vector{Float64}}` dictionary holds the centroid values $\\mu_1, \\dots, \\mu_K$ for each cluster, where keys are cluster indexes and values are the `m`-dimensional centroids (means) of the data points in that cluster. \n",
    "> * The `assignments::Vector{Int64}` field is an `n`-dimensional vector holding the clustered index that each data point is assigned to. We initialize both fields based on the initial random cluster assignment.\n",
    "\n",
    "_Fill in the missing code to build our clustering model_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "848bc561-923e-4a9d-b06b-881d003a4f5c",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "MethodError: no method matching rand(::Type{Float64}, ::Nothing)\nThe function `rand` exists, but no method is defined for this combination of argument types.\n\n\u001b[0mClosest candidates are:\n\u001b[0m  rand(::Type{X}, \u001b[91m::Integer\u001b[39m, Integer...) where X\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[33mRandom\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.12.4+0.aarch64.apple.darwin14/share/julia/stdlib/v1.12/Random/src/\u001b[39m\u001b[90m\u001b[4mRandom.jl:294\u001b[24m\u001b[39m\n\u001b[0m  rand(::Type{X}, \u001b[91m::NTuple{N, Int64} where N\u001b[39m) where X\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[33mRandom\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.12.4+0.aarch64.apple.darwin14/share/julia/stdlib/v1.12/Random/src/\u001b[39m\u001b[90m\u001b[4mRandom.jl:291\u001b[24m\u001b[39m\n\u001b[0m  rand(::Type{X}) where X\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[33mRandom\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.12.4+0.aarch64.apple.darwin14/share/julia/stdlib/v1.12/Random/src/\u001b[39m\u001b[90m\u001b[4mRandom.jl:261\u001b[24m\u001b[39m\n\u001b[0m  ...\n",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching rand(::Type{Float64}, ::Nothing)\nThe function `rand` exists, but no method is defined for this combination of argument types.\n\n\u001b[0mClosest candidates are:\n\u001b[0m  rand(::Type{X}, \u001b[91m::Integer\u001b[39m, Integer...) where X\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[33mRandom\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.12.4+0.aarch64.apple.darwin14/share/julia/stdlib/v1.12/Random/src/\u001b[39m\u001b[90m\u001b[4mRandom.jl:294\u001b[24m\u001b[39m\n\u001b[0m  rand(::Type{X}, \u001b[91m::NTuple{N, Int64} where N\u001b[39m) where X\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[33mRandom\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.12.4+0.aarch64.apple.darwin14/share/julia/stdlib/v1.12/Random/src/\u001b[39m\u001b[90m\u001b[4mRandom.jl:291\u001b[24m\u001b[39m\n\u001b[0m  rand(::Type{X}) where X\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[33mRandom\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.12.4+0.aarch64.apple.darwin14/share/julia/stdlib/v1.12/Random/src/\u001b[39m\u001b[90m\u001b[4mRandom.jl:261\u001b[24m\u001b[39m\n\u001b[0m  ...\n",
      "",
      "Stacktrace:",
      " [1] \u001b[0m\u001b[1mbuild\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mmodeltype\u001b[39m::\u001b[0mType\u001b[90m{…}\u001b[39m, \u001b[90mdata\u001b[39m::\u001b[0m@NamedTuple\u001b[90m{…}\u001b[39m\u001b[0m\u001b[1m)\u001b[22m",
      "\u001b[90m   @\u001b[39m \u001b[32mVLDataScienceMachineLearningPackage\u001b[39m \u001b[90m~/.julia/packages/VLDataScienceMachineLearningPackage/UqSv7/src/\u001b[39m\u001b[90m\u001b[4mFactory.jl:1283\u001b[24m\u001b[39m",
      " [2] top-level scope",
      "\u001b[90m   @\u001b[39m \u001b[90m\u001b[4mIn[28]:6\u001b[24m\u001b[39m",
      " [3] \u001b[0m\u001b[1meval\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mm\u001b[39m::\u001b[0mModule, \u001b[90me\u001b[39m::\u001b[0mAny\u001b[0m\u001b[1m)\u001b[22m",
      "\u001b[90m   @\u001b[39m \u001b[90mCore\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mboot.jl:489\u001b[24m\u001b[39m",
      "Some type information was truncated. Use `show(err)` to see complete types."
     ]
    }
   ],
   "source": [
    "# STUDENT TASK: Build the K-means model with build(...).\n",
    "# Complete the named tuple with the correct parameters\n",
    "# HINT: dimension should be the number of features (columns) in D\n",
    "# See solution notebook if you need help with the syntax\n",
    "\n",
    "model = build(MyNaiveKMeansClusteringAlgorithm, (\n",
    "        maxiter = maxiter,\n",
    "        dimension = nothing, # replace with size(D,2)\n",
    "        number_of_points = total_number_of_points,\n",
    "        K = K,\n",
    "        ϵ = ϵ,\n",
    "        dataset = nothing, # replace with D\n",
    "        scale_factor = 1.0,\n",
    "));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e69391-d3cd-4cae-8d06-b682dc4bf0ea",
   "metadata": {},
   "source": [
    "#### Visualize the initial centroids and assignments\n",
    "`Unhide` the code block below to see how we plotted the initial assignments and centroids. Each data point, i.e., feature vector (shown by the circles), is initially assigned to a random cluster, and the centroids dictionary is initialized based on the initial cluster assignment, where the centroids are shown as `+.`\n",
    "\n",
    "> __Summary__: Depending upon the case, i.e., the value of $\\bar{c}_{2}$, there will be two distinct (but randomly mixed up) clusters or a single (ish) cloud with mixed up values. The initial cluster centroids will be somewhere between the clouds for the `distinct` case and buried inside the cloud for the `overlapping` case. This is where [the K-means method](https://en.wikipedia.org/wiki/K-means_clustering) starts, i.e., its initial belief about how the data should be partitioned.\n",
    "\n",
    "Let's visualize the initial state:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a11834c9-8224-4176-b84c-b5f049a7b527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STUDENT TASK: After you build `model`, uncomment the block below.\n",
    "# (Visualization code is provided - just remove the #= and =# markers)\n",
    "#=\n",
    "let\n",
    "\n",
    "    dataset = D; # what dataset am I looking at?\n",
    "    horizontal_index = 1;\n",
    "    vertical_index = 2;\n",
    "    p = plot(bg=\"gray95\", background_color_outside=\"white\", framestyle = :box, fg_legend = :transparent); # make an empty plot\n",
    "   \n",
    "    assignments = copy(model.assignments);\n",
    "    for i ∈ eachindex(assignments);\n",
    "        a = assignments[i];        \n",
    "        scatter!([dataset[i, horizontal_index]], [dataset[i, vertical_index]], label=\"\", c=my_color_dictionary[a], msc=my_color_dictionary[a]);\n",
    "    end\n",
    "    current();\n",
    "\n",
    "    # plot the centroids -\n",
    "    centroids = copy(model.centroids);\n",
    "    for k ∈ 1:K\n",
    "        c = centroids[k]\n",
    "        scatter!([c[horizontal_index]], [c[vertical_index]], label=\"Centroid cluster $(k)\", msc=my_color_dictionary[k], c=my_color_dictionary[k], \n",
    "            ms=6, markerstrokewidth=2, markershape = :plus)\n",
    "    end\n",
    "    current();\n",
    "\n",
    "    xlabel!(\"Feature 1 (AU)\", fontsize=18);\n",
    "    ylabel!(\"Feature 2 (AU)\", fontsize=18);\n",
    "    title!(\"Case = $(case_label)\", fontsize=18)\n",
    "end\n",
    "=#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98d4b82-a2cb-4cb8-b185-efc1cadb4705",
   "metadata": {},
   "source": [
    "### Clustering\n",
    "We'll call [the `cluster(...)` method](https://varnerlab.github.io/VLDataScienceMachineLearningPackage.jl/dev/clustering/#VLDataScienceMachineLearningPackage.cluster) to refine our initial random cluster assignments and centroid values. \n",
    "\n",
    "> __What's going on?__ \n",
    ">\n",
    "> The method takes the data matrix `D::Array{<:Number,2}` which we want to cluster and the `model::MyNaiveKMeansClusteringAlgorithm` instance that we built above. Optional arguments include `verbose::Bool` to save data from each iteration (default `false`) and `d::Any` to specify the distance metric (default Euclidean distance from the `Distances.jl` package). \n",
    ">\n",
    "> The method returns cluster centroids, the assignments, and the number of iterations in a `results::NamedTuple`.\n",
    "\n",
    "Let's cluster the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7a4cf969-27cd-47e5-b006-fe9b34b31fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STUDENT TASK: Cluster the data and store the result.\n",
    "# Call cluster(...) with D, model, and optional arguments\n",
    "# HINT: Set verbose = true to save intermediate results\n",
    "# HINT: Use tmpdir = _PATH_TO_TMP to specify where to save (folder must exist)\n",
    "result = nothing; # Replace with cluster(D, model, verbose = true, tmpdir = _PATH_TO_TMP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e71d64-e1f6-4583-ab3e-9464dbda8f19",
   "metadata": {},
   "source": [
    "#### Visualize clustering results\n",
    "\n",
    "`Unhide` the code block below to see how we plotted the cluster results. In addition, we've overlayed the data centers and the radius lines to see how the clustered data looks compared with the clustered data. \n",
    "\n",
    "> __What do we expect to see?__\n",
    ">\n",
    "> * In the `distinct` case with two clusters, [K-means clustering](https://en.wikipedia.org/wiki/K-means_clustering) will produce clusters corresponding to a single `faux` label, i.e., the cluster will have either all orange or all blue elements that are contained in the radius one circle. \n",
    "> * In the `overlapping` case, there is a boundary between clusters that may have mixed data points. Note that because of the randomness of the initial assignment, sometimes cluster 2 (orange) will be on the left, and cluster 1 (blue) will be on the right, or vice-versa.\n",
    "\n",
    "Let's visualize the clustering results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3837778b-2bec-4cae-82a4-0da99f355a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STUDENT TASK: After you run clustering, uncomment the block below. \n",
    "# (Visualization code is provided - just remove the #= and =# markers)\n",
    "#=\n",
    "let\n",
    "\n",
    "    dataset = D;\n",
    "    horizontal_index = 1;\n",
    "    vertical_index = 2;\n",
    "    p = plot(bg=\"gray95\", background_color_outside=\"white\", framestyle = :box, fg_legend = :transparent); # make an empty plot\n",
    "    \n",
    "    assignments = result.assignments;\n",
    "    for i ∈ eachindex(assignments);\n",
    "        a = assignments[i];        \n",
    "        scatter!([dataset[i, horizontal_index]], [dataset[i, vertical_index]], label=\"\", c=my_color_dictionary[a], msc=my_color_dictionary[a]);\n",
    "    end\n",
    "    current();\n",
    "\n",
    "    # plot the centroids -\n",
    "    centroids = result.centroids;\n",
    "    for k ∈ 1:K\n",
    "        c = centroids[k]\n",
    "        scatter!([c[horizontal_index]], [c[vertical_index]], label=\"Centroid cluster $(k)\", msc=my_color_dictionary[k], c=my_color_dictionary[k], \n",
    "            ms=10, markerstrokewidth=2, markershape = :plus)\n",
    "    end\n",
    "    current();\n",
    "\n",
    "    circle_one = fixedcircle(c̄₁);\n",
    "    circle_two = fixedcircle(c̄₂);\n",
    "    plot!(circle_one[:,1], circle_one[:,2], lw=2, c=:black, ls=:dash, label=\"\")\n",
    "    plot!(circle_two[:,1], circle_two[:,2], lw=2, c=:black, ls=:dash, label=\"\") \n",
    "    scatter!([c̄₁[1]], [c̄₁[2]], ms=6, mec=:black, c=:white, label=\"\")\n",
    "    scatter!([c̄₂[1]], [c̄₂[2]], ms=6, mec=:black, c=:white, label=\"\")\n",
    "\n",
    "    xlabel!(\"Feature 1 (AU)\", fontsize=18);\n",
    "    ylabel!(\"Feature 2 (AU)\", fontsize=18);\n",
    "    title!(\"Case = $(case_label)\", fontsize=18)\n",
    "end\n",
    "=#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bad963d",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6872919-615b-48ac-b2f8-faca55659b6b",
   "metadata": {},
   "source": [
    "## Task 3: Analyzing the quality of the clusters\n",
    "In this task, we'll explore the _quality_ of the clusters as a function of different parameters. The quality (correctness) of clusters can be computed [in various ways](https://juliastats.org/Clustering.jl/stable/validate.html). \n",
    "\n",
    "> Here, we'll consider two methods to assess the quality of the clusters obtained from [the K-means clustering algorithm](docs/CHEME-5820-L1d-KMeans-Algorithm-Spring-2026.ipynb):\n",
    ">\n",
    "> * __Method 1__ uses [the silhouette score](docs/CHEME-5820-L1d-KMeans-Algorithm-Spring-2026.ipynb), which measures how similar an object is to its cluster (cohesion) compared to other clusters (separation), ranging from -1 to 1 where higher values indicate better matching. \n",
    ">* __Method 2__ computes the error rate by comparing cluster assignments to the `faux` labels to determine the fraction of incorrectly clustered points, similar to the [binary classification problem](https://en.wikipedia.org/wiki/Binary_classification) where feature vectors predict datapoint type.\n",
    "\n",
    "After we implement these two assessment methods, you'll answer some discussion questions about what this assessment data is telling us."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef978c8-2a21-4f43-9a3e-42cbf2b58742",
   "metadata": {},
   "source": [
    "#### Method 1: Silhouette score\n",
    "Assume that we have clustered the data into $K$ clusters.\n",
    "Let $C(\\mathbf{x}_i)$ denote the cluster that contains data point $\\mathbf{x}_i$, and let $d(\\mathbf{x}_i, \\mathbf{x}_j) = \\|\\mathbf{x}_i - \\mathbf{x}_j\\|_{2}$ denote the Euclidean distance between data points $\\mathbf{x}_i$ and $\\mathbf{x}_j$.\n",
    "Then, for a data point $\\mathbf{x}_i\\in C(\\mathbf{x}_i)$, let $a(i)$ denote the average distance between $\\mathbf{x}_i$ and all other points in the __same cluster__:\n",
    "$$\n",
    "\\begin{equation*}\n",
    "a(i) = \\frac{1}{|C(\\mathbf{x}_i)| - 1}\\sum_{\\mathbf{x}_m \\in C(\\mathbf{x}_i),\\; m \\ne i}d(\\mathbf{x}_i,\\mathbf{x}_m)\n",
    "\\end{equation*}\n",
    "$$\n",
    "The term $|C(\\mathbf{x}_i)|$ denotes the number of data points in the cluster containing $\\mathbf{x}_i$.\n",
    "Thus, $a(i)$ measures the compactness (cohesion) of the cluster. \n",
    "\n",
    "Next, we define $b(i)$ to be the smallest mean distance of data point $\\mathbf{x}_{i}$ to all points in any other cluster in which point $i$ is not a member. The cluster with this smallest mean dissimilarity is said to be the _neighboring cluster_ of data point $i$ because it is the next best-fit cluster for data point $i$:\n",
    "$$\n",
    "\\begin{equation*}\n",
    "b(i) = \\min_{C \\in \\mathcal{C},\\; C \\ne C(\\mathbf{x}_i)} \\; \\frac{1}{|C|} \\sum_{\\mathbf{x}_m \\in C} d(\\mathbf{x}_i, \\mathbf{x}_m)\n",
    "\\end{equation*}\n",
    "$$\n",
    "Putting it all together, the silhouette score $s(i)$ for data point $\\mathbf{x}_i$ is defined as:\n",
    "$$\n",
    "\\begin{equation*}\n",
    "s(i) = \\frac{b(i) - a(i)}{\\max\\{a(i), b(i)\\}}\\quad\\text{if}\\,|C(\\mathbf{x}_i)|>1\n",
    "\\end{equation*}\n",
    "$$\n",
    "If $|C(\\mathbf{x}_i)|=1$, then $s(i)=0$. This gives a silhouette score for each data point as:\n",
    "$$\n",
    "\\begin{equation*}\n",
    "   s(i) =\n",
    "   \\begin{cases}\n",
    "      1 - a(i)/b(i) & \\text{if } a(i) < b(i)\\\\ \n",
    "      0 & \\text{if } a(i) = b(i)\\\\\n",
    "      b(i)/a(i) - 1 & \\text{if } a(i) > b(i)\n",
    "   \\end{cases}\n",
    "\\end{equation*}\n",
    "$$\n",
    "This definition shows $-1\\leq s(i)\\leq 1$. \n",
    "The mean $s(i)$ of all data points in a cluster measures how tightly grouped the points in the cluster are. \n",
    "We've implemented the computation of the silhouette score in the `silhouette(...)` function defined above. _Call the `silhouette(...)` function to compute the silhouette score_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "28584426-7298-4bc7-bb81-e04d7f19dbaf",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# STUDENT TASK: Compute silhouette scores and the mean s̄.\n",
    "# Complete the code below to compute silhouette scores\n",
    "# HINT: The silhouette function returns a 3-column array: [a, b, s]\n",
    "# HINT: Use mean(...) to compute the average of column 3\n",
    "s̄, silhouette_result_array  = let\n",
    "    \n",
    "    # Get the cluster assignments from the result\n",
    "    a = nothing # Replace with result.assignments\n",
    "    \n",
    "    # Call silhouette function (returns array with columns: a, b, s)\n",
    "    silhouette_result_array = nothing # Replace with silhouette(D, a)\n",
    "    \n",
    "    # Compute the average silhouette score (column 3)\n",
    "    s̄ = nothing # Replace with mean(silhouette_result_array[:,3])\n",
    "    \n",
    "    s̄, silhouette_result_array # return data to the caller\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e0d4fa79-3be2-4cbf-a9db-2c1a8df3183d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STUDENT TASK: After computing s̄, print it here.\n",
    "# Uncomment the line below\n",
    "# println(\"The overall mean silhouette score for distance = $(distance) is: $(s̄)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb9fe5d-48f7-4f98-be83-3c93cded0d02",
   "metadata": {},
   "source": [
    "#### Method 2: Classification error rate\n",
    "This method quantifies how many times a point was placed in the correct cluster. Consider the binary case, i.e., $K = 2$. Because K-means labels can swap left/right, set `blue_is_left::Bool` based on the plot (blue = cluster 1, orange = cluster 2).\n",
    "\n",
    "Set the cluster orientation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aabb1ef6-c2e3-48ea-94aa-db16c7cb1cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "blue_is_left = false; # set true if the blue (cluster 1) cloud is leftmost, false if rightmost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061fb573-213e-4775-b70a-46abd410452f",
   "metadata": {},
   "source": [
    "The code block below computes the fraction of points that are _misclassified_ after mapping the K-means cluster labels to the `faux` labels. Set `blue_is_left` to indicate whether the blue (cluster 1) cloud is leftmost; if it is rightmost, the assignments are flipped before computing `error_fraction::Float64`. If $K \\ne 2$, a [@info statement is generated](https://docs.julialang.org/en/v1/stdlib/Logging/#Logging.@logmsg).\n",
    "\n",
    "Let's compute the error fraction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4852e2ff-c5e5-46f9-9d51-106e5c04ed63",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "FieldError: type Nothing has no field `assignments`; Nothing has no fields at all.",
     "output_type": "error",
     "traceback": [
      "FieldError: type Nothing has no field `assignments`; Nothing has no fields at all.",
      "",
      "Stacktrace:",
      " [1] \u001b[0m\u001b[1mgetproperty\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mx\u001b[39m::\u001b[0mNothing, \u001b[90mf\u001b[39m::\u001b[0mSymbol\u001b[0m\u001b[1m)\u001b[22m",
      "\u001b[90m   @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mBase_compiler.jl:54\u001b[24m\u001b[39m",
      " [2] top-level scope",
      "\u001b[90m   @\u001b[39m \u001b[90m\u001b[4mIn[43]:12\u001b[24m\u001b[39m",
      " [3] \u001b[0m\u001b[1meval\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mm\u001b[39m::\u001b[0mModule, \u001b[90me\u001b[39m::\u001b[0mAny\u001b[0m\u001b[1m)\u001b[22m",
      "\u001b[90m   @\u001b[39m \u001b[90mCore\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mboot.jl:489\u001b[24m\u001b[39m"
     ]
    }
   ],
   "source": [
    "# STUDENT TASK: Compute error_fraction for K == 2.\n",
    "# Complete the missing logic to compute classification errors\n",
    "# HINT: Compare mapped_label with the faux label D̂[i,3]\n",
    "# HINT: Count mismatches and divide by total_number_of_points\n",
    "\n",
    "error_fraction = let\n",
    "\n",
    "    error_fraction = nothing;\n",
    "    if (K == 2)\n",
    "\n",
    "        errors = 0.0;\n",
    "        a = result.assignments;\n",
    "        for i ∈ 1:total_number_of_points\n",
    "            mapped_label = a[i];\n",
    "            if (blue_is_left == false)\n",
    "                mapped_label = (mapped_label == 1) ? 2 : 1;\n",
    "            end\n",
    "\n",
    "            # TODO: Add 1.0 to errors if mapped_label doesn't match D̂[i,3]\n",
    "            # HINT: Use ternary operator → (condition) ? value_if_true : value_if_false\n",
    "            errors += nothing # TODO: Complete this line\n",
    "        end\n",
    "        error_fraction = (errors)/total_number_of_points;    \n",
    "    else\n",
    "        @info \"Alternative assessment method 2 not applicable.\"\n",
    "    end\n",
    "    error_fraction # return\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a9dfb091-6dc1-43b2-b472-95cf2c979147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STUDENT TASK: After computing error_fraction, display it here.\n",
    "# Uncomment the line below\n",
    "# error_fraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e80cb81-063c-45c7-a33e-a54ce2e7b99b",
   "metadata": {},
   "source": [
    "### Discussion questions (DQs)\n",
    "Run the notebook for $\\bar{c}_{2} = (10.0,1.0)$ (`distinct` case) and $\\bar{c}_{2} = (2.0,1.0)$ (`overlapping` case), and answer the following questions.\n",
    "\n",
    "__DQ1:__ Are the silhouette scores directly or indirectly proportional to the distance between the data cloud clusters? Why might you expect this relationship based on the definition, and what do you expect as the distance between cluster centers grows?\n",
    "\n",
    "> **To answer this question, consider:**\n",
    "> \n",
    "> - **(a)** Run the notebook with $\\bar{c}_{2} = (10.0, 1.0)$ (distinct case). What is the mean silhouette score $\\bar{s}$?\n",
    "> - **(b)** Run the notebook with $\\bar{c}_{2} = (2.0, 1.0)$ (overlapping case). What is the mean silhouette score $\\bar{s}$ now?\n",
    "> - **(c)** Based on parts (a) and (b), what pattern do you observe? Does $\\bar{s}$ increase or decrease as the distance between cluster centers decreases?\n",
    "> - **(d)** Looking at the silhouette score definition, why does this relationship make sense? Think about what happens to $b(i)$ (separation) as clusters move farther apart.\n",
    "> - **(e)** Prediction: What would you expect to happen to $\\bar{s}$ as the distance between centers approaches infinity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4dba0723-45c1-47cc-bf2c-bbd71f781a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your answer to DQ1 (either as a commented code cell, or as a markdown cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "47fe192e-0f3c-4c7a-8505-aecfc23b133c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STUDENT TASK: Set to true after you answer DQ1.\n",
    "did_I_answer_DQ1 = false; # update to true if answered DQ1 {true | false}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96cb998-dfcc-4dda-9cca-76d98f091d09",
   "metadata": {},
   "source": [
    "__DQ2__: In situations where _Method 2_ is applicable, does this alternative assessment criteria support what the silhouette scores are saying? Could you explain why _Method 2_ supports or refutes the silhouette scores? As the cluster centers become close, what error rate do you expect?\n",
    "\n",
    "> **To answer this question, consider:**\n",
    "> \n",
    "> - **(a)** For the distinct case ($\\bar{c}_{2} = (10.0, 1.0)$), what is the `error_fraction`? Make sure to set `blue_is_left` correctly based on your visualization.\n",
    "> - **(b)** For the overlapping case ($\\bar{c}_{2} = (2.0, 1.0)$), what is the `error_fraction`?\n",
    "> - **(c)** Compare the trends: When silhouette scores are high, is the error fraction low? When silhouette scores are low, is the error fraction high?\n",
    "> - **(d)** Do both methods agree that the distinct case has better clustering quality than the overlapping case? Explain.\n",
    "> - **(e)** As the cluster centers get closer and closer (distance → 2.08 and below), what do you predict will happen to the error rate? Would it approach 0%, 50%, or 100%? Why?\n",
    "> - **(f)** Why is Method 2 only applicable when $K = 2$? What information would you need to use this method for $K > 2$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2b779bae-aeea-47bc-8c34-9aed83f264b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your answer for DQ2 here (either as a commented code cell, or as a markdown cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6e80431f-eb85-4084-bf7a-8371eefc85d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STUDENT TASK: Set to true after you answer DQ2.\n",
    "did_I_answer_DQ2 = false; # update to true if answered DQ2 {true | false}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7cdb244-1495-4897-b835-1a1f3bd363b0",
   "metadata": {},
   "source": [
    "__DQ3__: For the `overlapping` case, explain what happens when you increase the number of clusters to $K = 3$?\n",
    "\n",
    "> **To answer this question:**\n",
    "> \n",
    "> - **(a)** Set $\\bar{c}_{2} = (2.0, 1.0)$ and $K = 3$, then re-run the entire notebook. What do you observe in the final clustering visualization? Where is the third cluster located?\n",
    "> - **(b)** What is the mean silhouette score $\\bar{s}$ with $K = 3$? Compare it to the $\\bar{s}$ you got with $K = 2$ for the same overlapping case.\n",
    "> - **(c)** Did increasing $K$ to 3 improve or worsen the clustering quality according to the silhouette score? Why or why not?\n",
    "> - **(d)** Looking at the visualization, do you see 3 natural groups in the data, or are you forcing K-means to find 3 clusters when there are really only 2?\n",
    "> - **(e)** What does this tell you about the importance of choosing the right value of $K$? What might happen if you set $K$ too high for your data?\n",
    "> - **(f)** Try $K = 4$ or $K = 5$. What pattern do you observe as $K$ increases beyond the true number of clusters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "28e4b141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your answer for DQ3 here (either as a commented code cell, or as a markdown cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d33ad868-44c0-4cc2-ae32-d2279c96a516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STUDENT TASK: Set to true after you answer DQ3.\n",
    "did_I_answer_DQ3 = false; # update to true if answered DQ3 {true | false}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ca2c3d-f7e3-49cc-947e-1ed3ac7a0015",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7c8c9f",
   "metadata": {},
   "source": [
    "## Summary\n",
    "K-means clustering successfully partitions distinct data clouds but fails predictably when circular clusters of radius 1 overlap beyond a critical distance threshold of 2.08 between centers.\n",
    "\n",
    "> __Key Takeaways:__\n",
    "> \n",
    "> * **Synthetic data reveals algorithmic limitations:** Generating controlled circular data clouds with variable center separation allows systematic testing of K-means behavior, demonstrating that the algorithm fails when center distance falls below the 2.08 threshold.\n",
    "> * **Multiple quality metrics provide complementary insights:** Silhouette scores measure cluster cohesion and separation, while classification error rates (comparing against known labels) quantify misclassification frequency, with both metrics declining as clusters overlap.\n",
    "> * **Lloyd's algorithm converges to incorrect solutions:** When data clouds overlap significantly, the K-means implementation converges successfully but produces incorrect cluster assignments, illustrating that convergence does not guarantee correctness.\n",
    "\n",
    "This example demonstrates a fundamental limitation of K-means clustering and motivates the need for alternative clustering methods when data exhibits non-convex or overlapping structures.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185b546b",
   "metadata": {},
   "source": [
    "## Tests\n",
    "In the code block below, we check some values in your notebook and give you feedback on which items are correct or different. `Unhide` the code block below (if you are curious) about how we implemented the tests and what we are testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "97bcfb67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 1: Generation of a synthetic dataset: \u001b[91m\u001b[1mError During Test\u001b[22m\u001b[39m at \u001b[39m\u001b[1mIn[57]:11\u001b[22m\n",
      "  Got exception outside of a @test\n",
      "  UndefVarError: `D̂` not defined in `Main`\n",
      "  Suggestion: add an appropriate import or assignment. This global was declared but not assigned.\n",
      "  Stacktrace:\n",
      "    [1] top-level scope\n",
      "  \u001b[90m    @\u001b[39m \u001b[90m\u001b[4mIn[57]:4\u001b[24m\u001b[39m\n",
      "    [2] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m    @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.12.4+0.aarch64.apple.darwin14/share/julia/stdlib/v1.12/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:1776\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "    [3] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m    @\u001b[39m \u001b[90m\u001b[4mIn[57]:12\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "    [4] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m    @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.12.4+0.aarch64.apple.darwin14/share/julia/stdlib/v1.12/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:1776\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "    [5] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m    @\u001b[39m \u001b[90m\u001b[4mIn[57]:12\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "    [6] \u001b[0m\u001b[1meval\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mm\u001b[39m::\u001b[0mModule, \u001b[90me\u001b[39m::\u001b[0mAny\u001b[0m\u001b[1m)\u001b[22m\n",
      "  \u001b[90m    @\u001b[39m \u001b[90mCore\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mboot.jl:489\u001b[24m\u001b[39m\n",
      "    [7] \u001b[0m\u001b[1minclude_string\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mmapexpr\u001b[39m::\u001b[0mtypeof(REPL.softscope), \u001b[90mmod\u001b[39m::\u001b[0mModule, \u001b[90mcode\u001b[39m::\u001b[0mString, \u001b[90mfilename\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n",
      "  \u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mloading.jl:2870\u001b[24m\u001b[39m\n",
      "    [8] \u001b[0m\u001b[1mexecute_request\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90msocket\u001b[39m::\u001b[0mZMQ.Socket, \u001b[90mkernel\u001b[39m::\u001b[0mIJulia.Kernel, \u001b[90mmsg\u001b[39m::\u001b[0mIJulia.Msg\u001b[0m\u001b[1m)\u001b[22m\n",
      "  \u001b[90m    @\u001b[39m \u001b[35mIJulia\u001b[39m \u001b[90m~/.julia/packages/IJulia/nBnGe/src/\u001b[39m\u001b[90m\u001b[4mexecute_request.jl:129\u001b[24m\u001b[39m\n",
      "    [9] \u001b[0m\u001b[1meventloop\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90msocket\u001b[39m::\u001b[0mZMQ.Socket, \u001b[90mkernel\u001b[39m::\u001b[0mIJulia.Kernel\u001b[0m\u001b[1m)\u001b[22m\n",
      "  \u001b[90m    @\u001b[39m \u001b[35mIJulia\u001b[39m \u001b[90m~/.julia/packages/IJulia/nBnGe/src/\u001b[39m\u001b[90m\u001b[4meventloop.jl:26\u001b[24m\u001b[39m\n",
      "   [10] \u001b[0m\u001b[1m(::IJulia.var\"#waitloop##2#waitloop##3\"{IJulia.Kernel})\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[0m\u001b[1m)\u001b[22m\n",
      "  \u001b[90m    @\u001b[39m \u001b[35mIJulia\u001b[39m \u001b[90m~/.julia/packages/IJulia/nBnGe/src/\u001b[39m\u001b[90m\u001b[4meventloop.jl:71\u001b[24m\u001b[39m\n",
      "Task 2: Cluster the data: \u001b[91m\u001b[1mTest Failed\u001b[22m\u001b[39m at \u001b[39m\u001b[1mIn[57]:19\u001b[22m\n",
      "  Expression: isnothing(D) == false\n",
      "   Evaluated: true == false\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "\u001b[90m   @\u001b[39m \u001b[90m\u001b[4mIn[57]:4\u001b[24m\u001b[39m\n",
      " [2] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "\u001b[90m   @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.12.4+0.aarch64.apple.darwin14/share/julia/stdlib/v1.12/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:1776\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [3] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "\u001b[90m   @\u001b[39m \u001b[90m\u001b[4mIn[57]:19\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [4] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "\u001b[90m   @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.12.4+0.aarch64.apple.darwin14/share/julia/stdlib/v1.12/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:1776\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [5] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "\u001b[90m   @\u001b[39m \u001b[90m\u001b[4mIn[57]:19\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [6] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "\u001b[90m   @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.12.4+0.aarch64.apple.darwin14/share/julia/stdlib/v1.12/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:680\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "Task 2: Cluster the data: \u001b[91m\u001b[1mError During Test\u001b[22m\u001b[39m at \u001b[39m\u001b[1mIn[57]:20\u001b[22m\n",
      "  Test threw exception\n",
      "  Expression: isnothing(model) == false\n",
      "  UndefVarError: `model` not defined in `Main`\n",
      "  Suggestion: add an appropriate import or assignment. This global was declared but not assigned.\n",
      "  Stacktrace:\n",
      "   [1] top-level scope\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m\u001b[4mIn[57]:4\u001b[24m\u001b[39m\n",
      "   [2] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.12.4+0.aarch64.apple.darwin14/share/julia/stdlib/v1.12/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:1776\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [3] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m\u001b[4mIn[57]:19\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [4] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.12.4+0.aarch64.apple.darwin14/share/julia/stdlib/v1.12/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:1776\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [5] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m\u001b[4mIn[57]:20\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [6] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.12.4+0.aarch64.apple.darwin14/share/julia/stdlib/v1.12/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:677\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "Task 2: Cluster the data: \u001b[91m\u001b[1mTest Failed\u001b[22m\u001b[39m at \u001b[39m\u001b[1mIn[57]:21\u001b[22m\n",
      "  Expression: isnothing(result) == false\n",
      "   Evaluated: true == false\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "\u001b[90m   @\u001b[39m \u001b[90m\u001b[4mIn[57]:4\u001b[24m\u001b[39m\n",
      " [2] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "\u001b[90m   @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.12.4+0.aarch64.apple.darwin14/share/julia/stdlib/v1.12/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:1776\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [3] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "\u001b[90m   @\u001b[39m \u001b[90m\u001b[4mIn[57]:19\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [4] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "\u001b[90m   @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.12.4+0.aarch64.apple.darwin14/share/julia/stdlib/v1.12/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:1776\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [5] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "\u001b[90m   @\u001b[39m \u001b[90m\u001b[4mIn[57]:21\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [6] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "\u001b[90m   @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.12.4+0.aarch64.apple.darwin14/share/julia/stdlib/v1.12/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:680\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "Task 3: Analyzing the quality of the clusters: \u001b[91m\u001b[1mTest Failed\u001b[22m\u001b[39m at \u001b[39m\u001b[1mIn[57]:25\u001b[22m\n",
      "  Expression: (s̄ isa Number) == true\n",
      "   Evaluated: false == true\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "\u001b[90m   @\u001b[39m \u001b[90m\u001b[4mIn[57]:4\u001b[24m\u001b[39m\n",
      " [2] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "\u001b[90m   @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.12.4+0.aarch64.apple.darwin14/share/julia/stdlib/v1.12/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:1776\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [3] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "\u001b[90m   @\u001b[39m \u001b[90m\u001b[4mIn[57]:25\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [4] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "\u001b[90m   @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.12.4+0.aarch64.apple.darwin14/share/julia/stdlib/v1.12/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:1776\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [5] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "\u001b[90m   @\u001b[39m \u001b[90m\u001b[4mIn[57]:25\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [6] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "\u001b[90m   @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.12.4+0.aarch64.apple.darwin14/share/julia/stdlib/v1.12/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:680\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "Task 3: Analyzing the quality of the clusters: \u001b[91m\u001b[1mTest Failed\u001b[22m\u001b[39m at \u001b[39m\u001b[1mIn[57]:26\u001b[22m\n",
      "  Expression: did_I_answer_DQ1 == true\n",
      "   Evaluated: false == true\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "\u001b[90m   @\u001b[39m \u001b[90m\u001b[4mIn[57]:4\u001b[24m\u001b[39m\n",
      " [2] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "\u001b[90m   @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.12.4+0.aarch64.apple.darwin14/share/julia/stdlib/v1.12/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:1776\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [3] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "\u001b[90m   @\u001b[39m \u001b[90m\u001b[4mIn[57]:25\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [4] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "\u001b[90m   @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.12.4+0.aarch64.apple.darwin14/share/julia/stdlib/v1.12/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:1776\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [5] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "\u001b[90m   @\u001b[39m \u001b[90m\u001b[4mIn[57]:26\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [6] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "\u001b[90m   @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.12.4+0.aarch64.apple.darwin14/share/julia/stdlib/v1.12/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:680\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "Task 3: Analyzing the quality of the clusters: \u001b[91m\u001b[1mTest Failed\u001b[22m\u001b[39m at \u001b[39m\u001b[1mIn[57]:27\u001b[22m\n",
      "  Expression: did_I_answer_DQ2 == true\n",
      "   Evaluated: false == true\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "\u001b[90m   @\u001b[39m \u001b[90m\u001b[4mIn[57]:4\u001b[24m\u001b[39m\n",
      " [2] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "\u001b[90m   @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.12.4+0.aarch64.apple.darwin14/share/julia/stdlib/v1.12/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:1776\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [3] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "\u001b[90m   @\u001b[39m \u001b[90m\u001b[4mIn[57]:25\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [4] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "\u001b[90m   @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.12.4+0.aarch64.apple.darwin14/share/julia/stdlib/v1.12/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:1776\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [5] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "\u001b[90m   @\u001b[39m \u001b[90m\u001b[4mIn[57]:27\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [6] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "\u001b[90m   @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.12.4+0.aarch64.apple.darwin14/share/julia/stdlib/v1.12/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:680\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "Task 3: Analyzing the quality of the clusters: \u001b[91m\u001b[1mTest Failed\u001b[22m\u001b[39m at \u001b[39m\u001b[1mIn[57]:28\u001b[22m\n",
      "  Expression: did_I_answer_DQ3 == true\n",
      "   Evaluated: false == true\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "\u001b[90m   @\u001b[39m \u001b[90m\u001b[4mIn[57]:4\u001b[24m\u001b[39m\n",
      " [2] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "\u001b[90m   @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.12.4+0.aarch64.apple.darwin14/share/julia/stdlib/v1.12/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:1776\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [3] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "\u001b[90m   @\u001b[39m \u001b[90m\u001b[4mIn[57]:25\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [4] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "\u001b[90m   @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.12.4+0.aarch64.apple.darwin14/share/julia/stdlib/v1.12/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:1776\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [5] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "\u001b[90m   @\u001b[39m \u001b[90m\u001b[4mIn[57]:28\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [6] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "\u001b[90m   @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.12.4+0.aarch64.apple.darwin14/share/julia/stdlib/v1.12/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:680\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "\u001b[0m\u001b[1mTest Summary:                                   | \u001b[22m\u001b[32m\u001b[1mPass  \u001b[22m\u001b[39m\u001b[91m\u001b[1mFail  \u001b[22m\u001b[39m\u001b[91m\u001b[1mError  \u001b[22m\u001b[39m\u001b[36m\u001b[1mTotal  \u001b[22m\u001b[39m\u001b[0m\u001b[1mTime\u001b[22m\n",
      "CHEME 5820 problem set 1 test suite             | \u001b[32m   4  \u001b[39m\u001b[91m   6  \u001b[39m\u001b[91m    2  \u001b[39m\u001b[36m   12  \u001b[39m\u001b[0m2.0s\n",
      "  Setup, Prerequisites and Data                 | \u001b[32m   4  \u001b[39m\u001b[91m      \u001b[39m\u001b[91m       \u001b[39m\u001b[36m    4  \u001b[39m\u001b[0m0.4s\n",
      "  Task 1: Generation of a synthetic dataset     | \u001b[32m      \u001b[39m\u001b[91m      \u001b[39m\u001b[91m    1  \u001b[39m\u001b[36m    1  \u001b[39m\u001b[0m0.5s\n",
      "  Task 2: Cluster the data                      | \u001b[32m      \u001b[39m\u001b[91m   2  \u001b[39m\u001b[91m    1  \u001b[39m\u001b[36m    3  \u001b[39m\u001b[0m1.1s\n",
      "  Task 3: Analyzing the quality of the clusters | \u001b[32m      \u001b[39m\u001b[91m   4  \u001b[39m\u001b[91m       \u001b[39m\u001b[36m    4  \u001b[39m\u001b[0m0.0s\n",
      "RNG of the outermost testset: Xoshiro(0x98f0f28da400df65, 0xb35833cd81348520, 0x8c6d39cbdbb377cf, 0x23bc89419a5ffcaf, 0x6b436fbcaabfae99)\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "\u001b[91mSome tests did not pass: 4 passed, 6 failed, 2 errored, 0 broken.\u001b[39m",
     "output_type": "error",
     "traceback": [
      "\u001b[91mSome tests did not pass: 4 passed, 6 failed, 2 errored, 0 broken.\u001b[39m",
      "",
      "Stacktrace:",
      " [1] \u001b[0m\u001b[1mfinish\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mts\u001b[39m::\u001b[0mTest.DefaultTestSet; \u001b[90mprint_results\u001b[39m::\u001b[0mBool\u001b[0m\u001b[1m)\u001b[22m",
      "\u001b[90m   @\u001b[39m \u001b[33mTest\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.12.4+0.aarch64.apple.darwin14/share/julia/stdlib/v1.12/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:1270\u001b[24m\u001b[39m",
      " [2] \u001b[0m\u001b[1mfinish\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mts\u001b[39m::\u001b[0mTest.DefaultTestSet\u001b[0m\u001b[1m)\u001b[22m",
      "\u001b[90m   @\u001b[39m \u001b[33mTest\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.12.4+0.aarch64.apple.darwin14/share/julia/stdlib/v1.12/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:1245\u001b[24m\u001b[39m",
      " [3] top-level scope",
      "\u001b[90m   @\u001b[39m \u001b[90m\u001b[4mIn[57]:4\u001b[24m\u001b[39m",
      " [4] \u001b[0m\u001b[1mmacro expansion\u001b[22m",
      "\u001b[90m   @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.12.4+0.aarch64.apple.darwin14/share/julia/stdlib/v1.12/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:1792\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m",
      " [5] \u001b[0m\u001b[1meval\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mm\u001b[39m::\u001b[0mModule, \u001b[90me\u001b[39m::\u001b[0mAny\u001b[0m\u001b[1m)\u001b[22m",
      "\u001b[90m   @\u001b[39m \u001b[90mCore\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mboot.jl:489\u001b[24m\u001b[39m"
     ]
    }
   ],
   "source": [
    "let \n",
    "    @testset verbose = true \"CHEME 5820 problem set 1 test suite\" begin\n",
    "        \n",
    "        @testset \"Setup, Prerequisites and Data\" begin\n",
    "            @test _DID_INCLUDE_FILE_GET_CALLED == true\n",
    "            @test number_label_one ≥ 2\n",
    "            @test number_label_two ≥ 2\n",
    "            @test K ≥ 2\n",
    "        end\n",
    "\n",
    "        @testset \"Task 1: Generation of a synthetic dataset\" begin\n",
    "            number_of_rows = size(D̂,1);\n",
    "            number_of_cols = size(D̂,2);\n",
    "            @test total_number_of_points == number_of_rows\n",
    "            @test number_of_cols == 3\n",
    "        end\n",
    "\n",
    "        @testset \"Task 2: Cluster the data\" begin\n",
    "            @test isnothing(D) == false\n",
    "            @test isnothing(model) == false\n",
    "            @test isnothing(result) == false\n",
    "        end\n",
    "\n",
    "        @testset \"Task 3: Analyzing the quality of the clusters\" begin\n",
    "            @test isa(s̄, Number) == true\n",
    "            @test did_I_answer_DQ1 == true\n",
    "            @test did_I_answer_DQ2 == true\n",
    "            @test did_I_answer_DQ3 == true\n",
    "        end\n",
    "    end\n",
    "end;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.6",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
